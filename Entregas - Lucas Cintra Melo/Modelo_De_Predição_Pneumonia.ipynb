{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "51778b45"
      },
      "source": [
        "# Instalações necessárias\n",
        "!pip install -q tensorflow kagglehub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91cc0e83"
      },
      "source": [
        "# Silencia mensagens do TF\n",
        "%env TF_CPP_MIN_LOG_LEVEL=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f924f26"
      },
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import kagglehub\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c97f32e8"
      },
      "source": [
        "# Baixa o dataset do kaggle\n",
        "path = kagglehub.dataset_download(\"tarunparuchur/pneumonia-classification-from-chest-x-rays\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bac10fa"
      },
      "source": [
        "# Caminhos principais\n",
        "train_dir = os.path.join(path, \"chest_xray/train\")\n",
        "val_dir   = os.path.join(path, \"chest_xray/val\")\n",
        "test_dir  = os.path.join(path, \"chest_xray/test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e8dc9d8"
      },
      "source": [
        "# Carregar as imagens com ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Normalização + aumento de dados (data augmentation)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=15,\n",
        "                                   zoom_range=0.1,\n",
        "                                   width_shift_range=0.1,\n",
        "                                   height_shift_range=0.1,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cbb2a7d"
      },
      "source": [
        "# Geradores\n",
        "batch_size = 32\n",
        "img_size = (150, 150)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte os generators do Kaggle em arrays\n",
        "def generator_to_numpy(generator):\n",
        "    x, y = [], []\n",
        "    for i in range(len(generator)):\n",
        "        imgs, labels = generator[i]\n",
        "        x.append(imgs)\n",
        "        y.append(labels)\n",
        "    return np.concatenate(x), np.concatenate(y)\n",
        "\n",
        "x_train_kaggle, y_train_kaggle = generator_to_numpy(train_generator)\n",
        "x_val_kaggle, y_val_kaggle     = generator_to_numpy(val_generator)\n",
        "x_test_kaggle, y_test_kaggle   = generator_to_numpy(test_generator)"
      ],
      "metadata": {
        "id": "kg5a0_c1jqUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "WVLFS4GGp-Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar o dataset do hugging face\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"hf-vision/chest-xray-pneumonia\")\n",
        "\n",
        "def preprocess(example):\n",
        "    image = example[\"image\"].convert(\"RGB\").resize(img_size)\n",
        "    image = np.array(image) / 255.0\n",
        "    return image, example[\"label\"]\n",
        "\n",
        "x_train_hf, y_train_hf = zip(*[preprocess(ex) for ex in ds[\"train\"]])\n",
        "x_val_hf, y_val_hf     = zip(*[preprocess(ex) for ex in ds[\"validation\"]])\n",
        "x_test_hf, y_test_hf   = zip(*[preprocess(ex) for ex in ds[\"test\"]])\n",
        "\n",
        "x_train_hf, y_train_hf = np.array(x_train_hf), np.array(y_train_hf)\n",
        "x_val_hf, y_val_hf     = np.array(x_val_hf), np.array(y_val_hf)\n",
        "x_test_hf, y_test_hf   = np.array(x_test_hf), np.array(y_test_hf)"
      ],
      "metadata": {
        "id": "gYOfGEz7j6Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para limitar por classe\n",
        "def limitar_por_classe(x, y, limite_por_classe=1000):\n",
        "    \"\"\"Recebe arrays X, y e retorna no máximo 'limite_por_classe' exemplos por classe\"\"\"\n",
        "    x_final, y_final = [], []\n",
        "\n",
        "    for classe in np.unique(y):\n",
        "        idxs = np.where(y == classe)[0]\n",
        "        np.random.shuffle(idxs)\n",
        "        idxs = idxs[:limite_por_classe]\n",
        "\n",
        "        x_final.append(x[idxs])\n",
        "        y_final.append(y[idxs])\n",
        "\n",
        "    return np.concatenate(x_final), np.concatenate(y_final)\n",
        "\n",
        "# ====== Aplicar limites ======\n",
        "\n",
        "# Treino\n",
        "x_train_kaggle, y_train_kaggle = limitar_por_classe(x_train_kaggle, y_train_kaggle, limite_por_classe=1000)\n",
        "x_train_hf,     y_train_hf     = limitar_por_classe(x_train_hf,     y_train_hf,     limite_por_classe=1000)\n",
        "\n",
        "# Validação\n",
        "x_val_kaggle, y_val_kaggle = limitar_por_classe(x_val_kaggle, y_val_kaggle, limite_por_classe=500)\n",
        "x_val_hf,     y_val_hf     = limitar_por_classe(x_val_hf,     y_val_hf,     limite_por_classe=500)\n",
        "\n",
        "# Teste\n",
        "x_test_kaggle, y_test_kaggle = limitar_por_classe(x_test_kaggle, y_test_kaggle, limite_por_classe=500)\n",
        "x_test_hf,     y_test_hf     = limitar_por_classe(x_test_hf,     y_test_hf,     limite_por_classe=500)\n"
      ],
      "metadata": {
        "id": "Y6Ori5MeQI47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Concatenar os dois datasets\n",
        "\n",
        "\n",
        "x_train = np.concatenate([x_train_kaggle, x_train_hf])\n",
        "y_train = np.concatenate([y_train_kaggle, y_train_hf])\n",
        "\n",
        "x_val   = np.concatenate([x_val_kaggle, x_val_hf])\n",
        "y_val   = np.concatenate([y_val_kaggle, y_val_hf])\n",
        "\n",
        "x_test  = np.concatenate([x_test_kaggle, x_test_hf])\n",
        "y_test  = np.concatenate([y_test_kaggle, y_test_hf])"
      ],
      "metadata": {
        "id": "TwopAgGpkUmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0c571d4"
      },
      "source": [
        "# Classes do problema\n",
        "nomes_classes = list(train_generator.class_indices.keys())\n",
        "print(\"Classes:\", nomes_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "980377d2"
      },
      "source": [
        "# Visualização de algumas imagens\n",
        "def visualiza_imagens(generator):\n",
        "    images, labels = next(generator)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for i in range(25):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.title(nomes_classes[int(labels[i])])\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "visualiza_imagens(train_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5599531f"
      },
      "source": [
        "# Importa base já treinada\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(150,150,3),\n",
        "    include_top=False,      # não usa as camadas finais originais\n",
        "    weights='imagenet'      # carrega pesos treinados no ImageNet\n",
        ")\n",
        "\n",
        "# Congela a base (não treina de novo os pesos dela)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Cria o modelo final\n",
        "modelo_lia = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),   # \"achata\" mantendo info espacial\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ef6492"
      },
      "source": [
        "# Compilação\n",
        "modelo_lia.compile(optimizer='adam',\n",
        "                   loss='binary_crossentropy',\n",
        "                   metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4608170"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(2000).batch(batch_size)\n",
        "val_ds   = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size)\n",
        "test_ds  = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Treinamento com mais épocas\n",
        "history = modelo_lia.fit(\n",
        "    train_ds,\n",
        "    epochs=5,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca0764d7"
      },
      "source": [
        "# Avaliação\n",
        "erro_teste, acc_teste = modelo_lia.evaluate(test_ds, verbose=2)\n",
        "print(\"\\nAcurácia com dados de Teste (Kaggle + HF):\", acc_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e18a540f"
      },
      "source": [
        "# Previsões no conjunto de teste combinado (Kaggle + HF)\n",
        "y_pred = modelo_lia.predict(test_ds)\n",
        "y_pred_classes = (y_pred > 0.8).astype(\"int32\").flatten()\n",
        "y_true = y_test   # já vem concatenado\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ba4368b"
      },
      "source": [
        "# Matriz de confusão\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=nomes_classes,\n",
        "            yticklabels=nomes_classes)\n",
        "plt.title('Matriz de Confusão - Pneumonia')\n",
        "plt.xlabel('Previsto')\n",
        "plt.ylabel('Real')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95d803ce"
      },
      "source": [
        "# Testando com uma imagem nova\n",
        "nova_imagem = Image.open(\"/content/teste2.jpg\")  # substitua pelo caminho da imagem\n",
        "nova_imagem = nova_imagem.resize(img_size)\n",
        "\n",
        "plt.imshow(nova_imagem)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "189d6056"
      },
      "source": [
        "# Prepara imagem para predição\n",
        "nova_imagem_array = np.array(nova_imagem) / 255.0\n",
        "nova_imagem_array = np.expand_dims(nova_imagem_array, axis=0)\n",
        "\n",
        "# Faz a predição\n",
        "previsao = modelo_lia.predict(nova_imagem_array)\n",
        "probabilidade = previsao[0][0]\n",
        "\n",
        "# Define a classe e a confiança\n",
        "if probabilidade > 0.5:\n",
        "    classe_prevista = nomes_classes[1]  # pneumonia\n",
        "    confianca = probabilidade * 100\n",
        "else:\n",
        "    classe_prevista = nomes_classes[0]  # normal\n",
        "    confianca = (1 - probabilidade) * 100\n",
        "\n",
        "print(f\"A nova imagem foi classificada como: {classe_prevista} com {confianca:.2f}% de confiança\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}